{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def tokenize(code):\n",
        "    \"\"\"\n",
        "    Tokenizes a given string of code.\n",
        "\n",
        "    Args:\n",
        "        code: The input code string.\n",
        "\n",
        "    Returns:\n",
        "        A list of tokens. Each token is a tuple containing the token type and its value.\n",
        "    \"\"\"\n",
        "    tokens = []\n",
        "\n",
        "    # Regular expressions for different token types\n",
        "    keywords = r'(if|else|while|for|int|float|string|return)'\n",
        "    operators = r'(\\+|-|\\*|/|=|<|>|<=|>=|==|!=)'\n",
        "    identifiers = r'[a-zA-Z_][a-zA-Z0-9_]*'\n",
        "    numbers = r'\\d+(\\.\\d+)?'\n",
        "    strings = r'\"[^\"]*\"' # Matches strings enclosed in double quotes\n",
        "    separators = r'(\\(|\\)|\\[|\\]|\\{|\\}|,|;)'\n",
        "    whitespace = r'\\s+'\n",
        "\n",
        "    # Combine all patterns into a single regular expression\n",
        "    pattern = '|'.join([keywords, operators, identifiers, numbers, strings, separators, whitespace])\n",
        "\n",
        "    for match in re.finditer(pattern, code):\n",
        "        token_value = match.group(0)\n",
        "\n",
        "        if re.match(keywords, token_value):\n",
        "            token_type = 'KEYWORD'\n",
        "        elif re.match(operators, token_value):\n",
        "            token_type = 'OPERATOR'\n",
        "        elif re.match(identifiers, token_value):\n",
        "            token_type = 'IDENTIFIER'\n",
        "        elif re.match(numbers, token_value):\n",
        "            token_type = 'NUMBER'\n",
        "        elif re.match(strings, token_value):\n",
        "            token_type = 'STRING'\n",
        "        elif re.match(separators, token_value):\n",
        "            token_type = 'SEPARATOR'\n",
        "        elif re.match(whitespace, token_value):\n",
        "            continue # Skip whitespace\n",
        "        else:\n",
        "            token_type = 'INVALID'\n",
        "\n",
        "        tokens.append((token_type, token_value))\n",
        "\n",
        "    return tokens\n",
        "\n",
        "code = \"\"\"\n",
        "int main() {\n",
        "  int x = 10;\n",
        "  if (x > 5) {\n",
        "    x = x + 1;\n",
        "  }\n",
        "  return 0;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "tokens = tokenize(code)\n",
        "\n",
        "for token_type, token_value in tokens:\n",
        "  print(f\"Token: {token_value}, Type: {token_type}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wguKWlUKagTJ",
        "outputId": "65d503d0-28e0-468d-8fe1-3ebcc0b14b13"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token: int, Type: KEYWORD\n",
            "Token: main, Type: IDENTIFIER\n",
            "Token: (, Type: SEPARATOR\n",
            "Token: ), Type: SEPARATOR\n",
            "Token: {, Type: SEPARATOR\n",
            "Token: int, Type: KEYWORD\n",
            "Token: x, Type: IDENTIFIER\n",
            "Token: =, Type: OPERATOR\n",
            "Token: 10, Type: NUMBER\n",
            "Token: ;, Type: SEPARATOR\n",
            "Token: if, Type: KEYWORD\n",
            "Token: (, Type: SEPARATOR\n",
            "Token: x, Type: IDENTIFIER\n",
            "Token: >, Type: OPERATOR\n",
            "Token: 5, Type: NUMBER\n",
            "Token: ), Type: SEPARATOR\n",
            "Token: {, Type: SEPARATOR\n",
            "Token: x, Type: IDENTIFIER\n",
            "Token: =, Type: OPERATOR\n",
            "Token: x, Type: IDENTIFIER\n",
            "Token: +, Type: OPERATOR\n",
            "Token: 1, Type: NUMBER\n",
            "Token: ;, Type: SEPARATOR\n",
            "Token: }, Type: SEPARATOR\n",
            "Token: return, Type: KEYWORD\n",
            "Token: 0, Type: NUMBER\n",
            "Token: ;, Type: SEPARATOR\n",
            "Token: }, Type: SEPARATOR\n"
          ]
        }
      ]
    }
  ]
}
